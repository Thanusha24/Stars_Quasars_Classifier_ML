{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.utils import resample,shuffle\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfpn(testSet, predictions):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][classcol] == predictions[x]:\n",
    "            if(testSet[x][classcol] == 1):\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if(predictions[x] ==1):\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    return (tp,tn,fp,fn)\n",
    "def findclass(df):\n",
    "    classs=None\n",
    "    columns=df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        if columns[i]=='class':\n",
    "            classs=i\n",
    "            break\n",
    "    return classs\n",
    "classcol=None\n",
    "def loaddataset(file,perc,trainset=[],testset=[]):\n",
    "    data=pd.read_csv(file)\n",
    "    df_maj = data[data['class'] == 1]\n",
    "    l = len(df_maj)\n",
    "    #print(len(df_maj))\n",
    "    df_min = data[data['class'] == 0]\n",
    "    df_minor_up = resample(df_min,replace=True,n_samples=l,random_state=123)\n",
    "    #print(len(df_minor_up))\n",
    "    df_upsampled = pd.concat([df_maj,df_minor_up])\n",
    "    df_upsampled=shuffle(df_upsampled)\n",
    "    df=df_upsampled.drop(['spectrometric_redshift','Unnamed: 0', 'galex_objid', 'sdss_objid','pred'],1)\n",
    "    global classcol \n",
    "    classcol=findclass(df)\n",
    "    df=df[1:]\n",
    "    dataset=list(df.values.tolist())\n",
    "    length=len(dataset[0])\n",
    "    count=0\n",
    "    split=(len(dataset)-1)*perc\n",
    "    for x in range(1,len(dataset)-1):\n",
    "        for y in range(1,length):\n",
    "            dataset[x][y]=float(dataset[x][y])\n",
    "        if(count<split):\n",
    "            trainset.append(dataset[x])\n",
    "                #print(dataset[x])\n",
    "        else:\n",
    "            testset.append(dataset[x])\n",
    "        count+=1\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow(float(instance1[x]) - float(instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)\n",
    "    for x in range(1,len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][classcol]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "        sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][classcol] == predictions[x]:\n",
    "            correct += 1\n",
    "    print(len(testSet))\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cross validation split\n",
    "def main(k):\n",
    "    seed(1)\n",
    "    trainingSet = []\n",
    "    testset = []\n",
    "    loaddataset('cat3.csv',0.8,trainingSet,testset)\n",
    "    dataset = trainingSet+testset\n",
    "    n_folds = 5\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    predictions=[]\n",
    "    test = []\n",
    "    for i in range(n_folds):\n",
    "        new_train = [item for item in dataset if item not in folds[i]]\n",
    "        new_test = folds[i]\n",
    "        print(i,\" training set\")\n",
    "\n",
    "        for x in range(len(new_test)):\n",
    "            test.append(new_test[x])\n",
    "            neighbors = getNeighbors(new_train, new_test[x], k)\n",
    "            result = getResponse(neighbors)\n",
    "            predictions.append(result)\n",
    "            #print('>predicted=' + str(result) + ', actual=' + str(testSet[x][12]))\n",
    "    l = tfpn(test,predictions)\n",
    "    TP = l[0]\n",
    "    TN = l[1]\n",
    "    FP = l[2]\n",
    "    FN = l[3]\n",
    "\n",
    "    print(\"true positive :\",TP)\n",
    "    print(\"true negative :\",TN)\n",
    "    print(\"false positive :\",FP)\n",
    "    print(\"false negative :\",FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    print( 'Sensitivity:{}'.format(TPR))\n",
    "    TNR = TN/(TN+FP)\n",
    "    print( 'Specificity:{}'.format(TNR))\n",
    "    Precision = TP/(TP+FP)\n",
    "    print( 'Precision:{}'.format(Precision))\n",
    "    Recall = TP/(TP+FN)\n",
    "    print( 'Recall:{}'.format(Recall))\n",
    "    Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    print( 'Accuracy:{}'.format(Acc))\n",
    "    Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "    print( 'FScore:{}'.format(Fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  training set\n",
      "1  training set\n",
      "2  training set\n",
      "3  training set\n",
      "4  training set\n",
      "true positive : 3792\n",
      "true negative : 2271\n",
      "false positive : 1552\n",
      "false negative : 30\n",
      "Sensitivity:0.9921507064364207\n",
      "Specificity:0.5940360973057808\n",
      "Precision:0.7095808383233533\n",
      "Recall:0.9921507064364207\n",
      "Accuracy:0.7930673642903858\n",
      "FScore:0.8274056295003274\n"
     ]
    }
   ],
   "source": [
    "main(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  training set\n",
      "1  training set\n",
      "2  training set\n",
      "3  training set\n",
      "4  training set\n",
      "true positive : 3766\n",
      "true negative : 2661\n",
      "false positive : 1163\n",
      "false negative : 55\n",
      "Sensitivity:0.9856058623397016\n",
      "Specificity:0.6958682008368201\n",
      "Precision:0.7640495029417732\n",
      "Recall:0.9856058623397016\n",
      "Accuracy:0.8406801831262263\n",
      "FScore:0.8608\n"
     ]
    }
   ],
   "source": [
    "main(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  training set\n",
      "1  training set\n",
      "2  training set\n",
      "3  training set\n",
      "4  training set\n",
      "true positive : 3763\n",
      "true negative : 2502\n",
      "false positive : 1321\n",
      "false negative : 59\n",
      "Sensitivity:0.9845630559916274\n",
      "Specificity:0.6544598482866858\n",
      "Precision:0.7401652242328874\n",
      "Recall:0.9845630559916274\n",
      "Accuracy:0.8194898626553303\n",
      "FScore:0.8450482820570401\n"
     ]
    }
   ],
   "source": [
    "main(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
